"""
Faturalama ve Ã¶deme iÅŸlemleri iÃ§in Ã¶zel agent
"""

from langchain_ollama import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate


class FaturaAgent:
    """Faturalama ve Ã¶deme iÅŸlemleri iÃ§in Ã¶zel agent sÄ±nÄ±fÄ±"""
    
    def __init__(self, model_name: str = "gemma3:latest"):
        """
        Fatura Agent'i baÅŸlatÄ±r
        
        Args:
            model_name: Ollama'da kullanÄ±lacak model adÄ±
        """
        self.llm = OllamaLLM(
            model=model_name,
            base_url="http://localhost:11434"
        )
        
        # Faturalama konularÄ±na Ã¶zel prompt
        self.prompt = ChatPromptTemplate.from_template(
            """Sen TelekomTÃ¼rk'Ã¼n faturalama departmanÄ±ndan bir uzmansÄ±n. 
            MÃ¼ÅŸterilerin fatura, Ã¶deme, borÃ§ ve bakiye konularÄ±nda yardÄ±mcÄ± oluyorsun.
            
            Hizmetlerin:
            - Fatura sorgulama ve detaylarÄ±
            - Ã–deme yÃ¶ntemleri ve planlarÄ±
            - BorÃ§ yapÄ±landÄ±rma
            - Bakiye sorgularÄ±
            - Tahsilat sÃ¼reÃ§leri
            - Fatura itirazlarÄ±
            
            MÃ¼ÅŸteriye profesyonel, anlayÄ±ÅŸlÄ± ve Ã§Ã¶zÃ¼m odaklÄ± yaklaÅŸ.
            Gerekirse adÄ±m adÄ±m yÃ¶nlendirme yap.
            
            MÃ¼ÅŸteri talebi: {user_input}
            
            Faturalama UzmanÄ± YanÄ±tÄ±:"""
        )
    
    def handle_billing_request(self, user_input: str) -> str:
        """
        Faturalama talebini iÅŸler
        
        Args:
            user_input: MÃ¼ÅŸterinin faturalama talebi
            
        Returns:
            Faturalama uzmanÄ±nÄ±n yanÄ±tÄ±
        """
        print(f"ğŸ’³ Faturalama DepartmanÄ±: Talep iÅŸleniyor...")
        
        # Prompt'u hazÄ±rla ve LLM'e gÃ¶nder
        formatted_prompt = self.prompt.format(user_input=user_input)
        response = self.llm.invoke(formatted_prompt)
        
        return response
